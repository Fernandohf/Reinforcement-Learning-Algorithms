[DEFAULT]

ACTION_SIZE:
  desc: Size of actions for each agent
  value: 2
ACTOR_GRADIENT_CLIP_VALUE:
  desc: Max gradient modulus for clipping
  value: 5
ACTOR_LR:
  desc: Learning rate of the actor
  value: 0.001
ACTOR_WEIGHT_DECAY:
  desc: Actor L2 weight decay
  value: 0.0
BATCH_SIZE:
  desc: Mini-batch size
  value: 256
BUFFER_SIZE:
  desc: Replay buffer size
  value: 1000000
CRITIC_GRADIENT_CLIP_VALUE:
  desc: Max gradient modulus for clipping
  value: 1
CRITIC_LR:
  desc: Learning rate of the critic
  value: 0.001
CRITIC_WEIGHT_DECAY:
  desc: Critic L2 weight decay
  value: 1.0e-05
DEVICE:
  desc: Device being trained (cuda/cpu)
  value: cuda
GAMMA:
  desc: Discount factor
  value: 0.99
MAX_T:
  desc: Maximum number of time steps
  value: 2000
NOISE_TYPE:
  desc: Type of noise used (normal/ou)
  value: normal
N_AGENTS:
  desc: Total number of agents
  value: 2
N_EPISODES:
  desc: Number of episodes to run the algorithm
  value: 2000
N_EPS_BETA:
  desc: Normal noise decay rate
  value: 0.1
N_EPS_INIT:
  desc: Normal noise initial decay value
  value: 1
N_EPS_MIN:
  desc: Normal noise min decay value
  value: 0.01
N_MEAN:
  desc: Normal noise mu parameters
  value: 0.0
N_SIGMA:
  desc: Normal noise sigma parameters
  value: 0.4
OU_SIGMA:
  desc: OU noise sigma parameter
  value: 0.01
OU_THETA:
  desc: OU noise theta parameter
  value: 0.01
PRINT_EVERY:
  desc: Reporting interval
  value: 100
SEED:
  desc: Random seed
  value: 42
STATE_SIZE:
  desc: Size of the state for each agent
  value: 24
SUCCESS_SCORE:
  desc: Score to save the model and solve the environment
  value: 0.5
TAU:
  desc: Soft update of target parameters
  value: 0.005
UPDATE_EVERY:
  desc: Wait for more experiences before update
  value: 1
WANDB:
  desc: Wether or not save results on W&B
  value: true
